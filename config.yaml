retrieval:
  top_k_faiss: 15
  top_k_bm25: 15
  top_k_final: 6
  alpha: 0.6            # вес FAISS в гибриде (1-alpha для BM25)

graph:
  enable: true
  k_hop: 1              # 0/1/2 – глубина расширения
  max_neighbors: 8      # ограничение фактов из графа на вопрос

context:
  max_chars: 7000       # ограничение на общий контекст (примерно под 8–16k токенов моделей)
  snippet_chars: 900    # сколько символов брать из каждого чанка

model:
  provider: gemini      # openai | local
  name: gemini-2.0-flash    # или любой доступный
  retrieval_model: paraphrase-multilingual-MiniLM-L12-v2
  max_tokens: 400
  temperature: 0.7

paths:
  faiss: embeddings/index.faiss
  meta: embeddings/metadata.parquet
  bm25: embeddings/bm25.pkl
  graph_json: graph/graph.json
  chunks_jsonl: data/chunks/all_chunks.jsonl